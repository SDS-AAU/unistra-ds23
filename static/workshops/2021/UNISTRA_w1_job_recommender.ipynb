{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNISTRA_w1_job_recommender.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6BUa1wwt4Uxd0e66D5/Ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/UNISTRA-DS-2022/blob/master/static/workshops/2021/UNISTRA_w1_job_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LPxCZu2yRUt"
      },
      "outputs": [],
      "source": [
        "# install kaggle package\n",
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make folder for api key\n",
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "nb-Ew-Diyo4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy key into folder\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "DpG5-MA3zK7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change access permissions\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "72Cd3LJ_zXBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if worked\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPoVet-TzXcZ",
        "outputId": "e339724f-d690-403e-8163-890c500ab847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                              title                                               size  lastUpdated          downloadCount  \n",
            "---------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "yasserh/wine-quality-dataset                                     Wine Quality Dataset                                21KB  2022-01-15 19:15:11           7916  \n",
            "mkoklu42/pistachio-dataset                                       Pistachio Dataset                                    2MB  2022-02-11 21:06:50             99  \n",
            "prasertk/netflix-subscription-price-in-different-countries       Netflix subscription fee in different countries      3KB  2022-01-15 07:06:09           6058  \n",
            "majyhain/height-of-male-and-female-by-country-2022               Height of Male and Female by Country 2022            4KB  2022-02-02 00:40:19           3273  \n",
            "ashishjangra27/ted-talks                                         TED Talks                                          298KB  2022-02-23 15:16:08            721  \n",
            "jainilcoder/netflix-stock-price-prediction                       Netflix Stock Price Prediction                      21KB  2022-02-05 05:06:10           1196  \n",
            "shivavashishtha/shark-tank-india-dataset                         Shark Tank India Dataset                             4KB  2022-02-24 12:57:31            444  \n",
            "mkoklu42/pumpkin-seeds-dataset                                   Pumpkin Seeds Dataset                              393KB  2022-02-08 15:54:27            459  \n",
            "sanjeetsinghnaik/top-1000-highest-grossing-movies                Top 1000 Highest Grossing Movies                   106KB  2022-01-15 16:26:14           4032  \n",
            "mkoklu42/acoustic-extinguisher-fire-dataset                      Acoustic Extinguisher Fire Dataset                 620KB  2022-02-09 17:59:52             65  \n",
            "bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows    Ukraine Conflict Twitter Dataset (2.28M tweets)    521MB  2022-03-02 01:37:47            194  \n",
            "georgesaavedra/covid19-dataset                                   COVID-19 dataset                                     9MB  2022-02-25 19:13:10           3246  \n",
            "soumyadiptadas/products-sales-timeseries-data                    Products sales time-series data                      1KB  2022-02-24 08:21:51            351  \n",
            "prasertk/michelinstar-restaurants                                Michelin \"star\" restaurants                        364KB  2022-02-23 00:28:16            372  \n",
            "soumyadiptadas/students-math-score-for-different-teaching-style  Student's math score for different teaching style    2KB  2022-02-23 12:36:06            554  \n",
            "robikscube/ubiquant-parquet                                      Ubiquant Competition Data in Parquet Format         13GB  2022-01-19 14:18:59           2246  \n",
            "mkoklu42/dry-bean-dataset                                        Dry Bean Dataset                                     2MB  2022-02-08 12:36:26             44  \n",
            "mkoklu42/rice-msc-dataset                                        Rice MSC Dataset                                   102MB  2022-02-08 12:27:51             78  \n",
            "prokaggler/global-mobility-data-during-covid-19                  Global Mobility Data during Covid 19                67MB  2022-02-23 13:37:41            216  \n",
            "datasnaek/youtube-new                                            Trending YouTube Video Statistics                  201MB  2019-06-03 00:56:47         167230  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d kandij/job-recommendation-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKIcmbJFzh5I",
        "outputId": "3b3783aa-21e6-414d-fa1e-c381f98f1d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading job-recommendation-datasets.zip to /content\n",
            " 94% 49.0M/52.4M [00:01<00:00, 27.0MB/s]\n",
            "100% 52.4M/52.4M [00:02<00:00, 27.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/job-recommendation-datasets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDZyQjUjzvxc",
        "outputId": "9a50bd0e-6bd0-4964-dc06-ca00eff39f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/job-recommendation-datasets.zip\n",
            "  inflating: Combined_Jobs_Final.csv  \n",
            "  inflating: Experience.csv          \n",
            "  inflating: Job_Views.csv           \n",
            "  inflating: Positions_Of_Interest.csv  \n",
            "  inflating: job_data.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "#instantiating English module\n",
        "nlp = spacy.load('en')"
      ],
      "metadata": {
        "id": "Q05CJcSTz5co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs = pd.read_csv('/content/Combined_Jobs_Final.csv')\n",
        "df_views = pd.read_csv('/content/Job_Views.csv')\n",
        "df_poi = pd.read_csv('/content/Positions_Of_Interest.csv')\n",
        "df_exp = pd.read_csv('/content/Experience.csv')\n"
      ],
      "metadata": {
        "id": "pbdDsMaA0xl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6ERkhwm1rzi",
        "outputId": "6097d8bb-836d-4809-8e9d-244b04fc4682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 84090 entries, 0 to 84089\n",
            "Data columns (total 23 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Job.ID              84090 non-null  int64  \n",
            " 1   Provider            84090 non-null  int64  \n",
            " 2   Status              84090 non-null  object \n",
            " 3   Slug                84090 non-null  object \n",
            " 4   Title               84090 non-null  object \n",
            " 5   Position            84090 non-null  object \n",
            " 6   Company             81819 non-null  object \n",
            " 7   City                83955 non-null  object \n",
            " 8   State.Name          83919 non-null  object \n",
            " 9   State.Code          83919 non-null  object \n",
            " 10  Address             36 non-null     object \n",
            " 11  Latitude            84090 non-null  float64\n",
            " 12  Longitude           84090 non-null  float64\n",
            " 13  Industry            267 non-null    object \n",
            " 14  Job.Description     84034 non-null  object \n",
            " 15  Requirements        0 non-null      float64\n",
            " 16  Salary              229 non-null    float64\n",
            " 17  Listing.Start       83407 non-null  object \n",
            " 18  Listing.End         83923 non-null  object \n",
            " 19  Employment.Type     84080 non-null  object \n",
            " 20  Education.Required  83823 non-null  object \n",
            " 21  Created.At          84090 non-null  object \n",
            " 22  Updated.At          84090 non-null  object \n",
            "dtypes: float64(4), int64(2), object(17)\n",
            "memory usage: 14.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate several columns into one text\n",
        "df_jobs['text'] = df_jobs['Title'].str.cat(df_jobs['Position'].astype(str), sep=' ').str.cat(df_jobs['Company'].astype(str), sep=' ').str.cat(df_jobs['Job.Description'].astype(str), sep=' ')"
      ],
      "metadata": {
        "id": "Zv4mGoMJ19KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# progress bar\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "5WPjXcaN2IXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how long would it take to run it with plain spacy?\n",
        "\n",
        "%%time\n",
        "nlp(df_jobs['text'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JlAnFyI2ydu",
        "outputId": "ff16de94-aced-4787-8ce5-138216e203c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 72.9 ms, sys: 3.46 ms, total: 76.4 ms\n",
            "Wall time: 82.9 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Kitchen Staff/Chef @ Claude Lane Kitchen Staff/Chef Claude Lane  \n",
              "\n",
              "New French Brasserie in S.F. Financial District Seeks Chef\n",
              "We are seeking an energetic, dynamic chef to take charge and grow with our company. Our ideal candidate is a motivated self-starter, has a great work ethic and is ready for the challenge of building their own team with executive support. \n",
              "\n",
              "This position is a perfect fit for a talented chef ready to take the next step, someone who can multi task in a high volume kitchen and has exceptional organizational skills. Position requirements are experience with French cuisine, a minimum of 5 years as a sous chef in high volume, full service restaurant. He or she must be a team player, leading by example and working side by side with other members of the team. \n",
              "\n",
              "Computer and management skills are a must, as are experience in ordering, inventory and cost control. The right candidate will have previously demonstrated an understanding of leadership and accountability, and an infectious, energetic approach to problem solving and facing challenges. \n",
              "\n",
              "We are an equal opportunity employer. Qualified applicants are considered for employment without regard to age, race, religion, sex, national origin, sexual orientation, disability, or veteran status. "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run that for all? That is 0.71h - too long\n",
        "60*84000/1000/3600"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI0AVcdz2_Bc",
        "outputId": "398b94ba-bcd9-4c15-97b5-27bc65acda7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run progress bare and clean up using spacy but without some heavy parts of the pipeline\n",
        "\n",
        "%%time\n",
        "clean_text = []\n",
        "\n",
        "\n",
        "pbar = tqdm.tqdm(total=len(df_jobs['text']),position=0, leave=True)\n",
        "\n",
        "for text in nlp.pipe(df_jobs['text'], disable=[\"tagger\", \"parser\", \"ner\"]):\n",
        "\n",
        "  txt = [token.lemma_.lower() for token in text \n",
        "         if token.is_alpha \n",
        "         and not token.is_stop \n",
        "         and not token.is_punct]\n",
        "\n",
        "  clean_text.append(txt)\n",
        "\n",
        "  pbar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZkmhvPE3abm",
        "outputId": "69038975-e238-453d-bab4-cd1f47f73eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 84036/84090 [02:38<00:00, 608.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 31s, sys: 2.21 s, total: 2min 33s\n",
            "Wall time: 2min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs['clean_text'] = clean_text"
      ],
      "metadata": {
        "id": "5WVpJcyb37kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs['clean_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6uhPW6044rV",
        "outputId": "20f7a763-504f-4278-8873-a6fd43122bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [server, tacolicious, server, tacolicious, tac...\n",
              "1        [kitchen, staff, chef, claude, lane, kitchen, ...\n",
              "2        [bartender, machka, restaurants, bartender, ma...\n",
              "3        [server, teriyaki, house, server, teriyaki, ho...\n",
              "4        [kitchen, staff, chef, rosa, mexicano, sunset,...\n",
              "                               ...                        \n",
              "84085    [book, keeper, national, japanese, american, h...\n",
              "84086    [kitchen, staff, chef, emporio, rulli, kitchen...\n",
              "84087    [driver, onigilly, driver, onigilly, onigilly,...\n",
              "84088    [line, cook, machka, restaurants, line, cook, ...\n",
              "84089    [cashier, kazoo, restaurant, cashier, kazoo, r...\n",
              "Name: clean_text, Length: 84090, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs['clean_text'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-7Zxnxl468H",
        "outputId": "97a53665-93c4-4362-97f1-9de6d1b18d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update gensim\n",
        "!pip install --upgrade gensim -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8OY1Usi5pWZ",
        "outputId": "ee70ca04-85bb-42d7-bfb5-28f954c2c877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get tooling for Word2Vec model\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "-uAYYpdW59Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enable logging\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "metadata": {
        "id": "0OOKe9av6j26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train word2vec model\n",
        "w2v_model = Word2Vec(sentences=df_jobs['clean_text'], vector_size=300, window=5, min_count=2, workers=2, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqpoP6Mc8WNt",
        "outputId": "cc579575-99cf-4f64-98fe-6be17961145f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-02 09:23:58,319 : INFO : collecting all words and their counts\n",
            "2022-03-02 09:23:58,332 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-03-02 09:23:59,112 : INFO : PROGRESS: at sentence #10000, processed 1489501 words, keeping 18094 word types\n",
            "2022-03-02 09:24:00,211 : INFO : PROGRESS: at sentence #20000, processed 2801776 words, keeping 25505 word types\n",
            "2022-03-02 09:24:01,793 : INFO : PROGRESS: at sentence #30000, processed 4383902 words, keeping 30826 word types\n",
            "2022-03-02 09:24:02,893 : INFO : PROGRESS: at sentence #40000, processed 5723039 words, keeping 35286 word types\n",
            "2022-03-02 09:24:04,111 : INFO : PROGRESS: at sentence #50000, processed 7118565 words, keeping 39058 word types\n",
            "2022-03-02 09:24:04,879 : INFO : PROGRESS: at sentence #60000, processed 8409519 words, keeping 42530 word types\n",
            "2022-03-02 09:24:05,753 : INFO : PROGRESS: at sentence #70000, processed 9822031 words, keeping 45756 word types\n",
            "2022-03-02 09:24:06,588 : INFO : PROGRESS: at sentence #80000, processed 11324826 words, keeping 48540 word types\n",
            "2022-03-02 09:24:06,876 : INFO : collected 49783 word types from a corpus of 11925051 raw words and 84090 sentences\n",
            "2022-03-02 09:24:06,886 : INFO : Creating a fresh vocabulary\n",
            "2022-03-02 09:24:07,333 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 33071 unique words (66.4303075347006%% of original 49783, drops 16712)', 'datetime': '2022-03-02T09:24:07.333654', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-03-02 09:24:07,337 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 11908339 word corpus (99.85985804169727%% of original 11925051, drops 16712)', 'datetime': '2022-03-02T09:24:07.337845', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-03-02 09:24:07,848 : INFO : deleting the raw counts dictionary of 49783 items\n",
            "2022-03-02 09:24:07,858 : INFO : sample=0.001 downsamples 39 most-common words\n",
            "2022-03-02 09:24:07,860 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 11122819.810304202 word corpus (93.4%% of prior 11908339)', 'datetime': '2022-03-02T09:24:07.860463', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'prepare_vocab'}\n",
            "2022-03-02 09:24:08,646 : INFO : estimated required memory for 33071 words and 300 dimensions: 95905900 bytes\n",
            "2022-03-02 09:24:08,647 : INFO : resetting layer weights\n",
            "2022-03-02 09:24:08,914 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-02T09:24:08.914230', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'build_vocab'}\n",
            "2022-03-02 09:24:08,918 : INFO : Word2Vec lifecycle event {'msg': 'training model with 2 workers on 33071 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-02T09:24:08.918792', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-03-02 09:24:09,964 : INFO : EPOCH 1 - PROGRESS: at 1.81% examples, 208058 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:11,030 : INFO : EPOCH 1 - PROGRESS: at 3.66% examples, 216050 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:12,156 : INFO : EPOCH 1 - PROGRESS: at 5.50% examples, 211959 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:13,186 : INFO : EPOCH 1 - PROGRESS: at 7.10% examples, 199455 words/s, in_qsize 3, out_qsize 1\n",
            "2022-03-02 09:24:14,200 : INFO : EPOCH 1 - PROGRESS: at 8.93% examples, 200963 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:15,279 : INFO : EPOCH 1 - PROGRESS: at 10.65% examples, 195820 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:16,354 : INFO : EPOCH 1 - PROGRESS: at 12.54% examples, 195955 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:17,393 : INFO : EPOCH 1 - PROGRESS: at 14.51% examples, 196950 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:18,412 : INFO : EPOCH 1 - PROGRESS: at 16.28% examples, 193308 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:19,434 : INFO : EPOCH 1 - PROGRESS: at 20.31% examples, 214024 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:20,458 : INFO : EPOCH 1 - PROGRESS: at 24.41% examples, 232408 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:21,464 : INFO : EPOCH 1 - PROGRESS: at 28.42% examples, 247608 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:22,488 : INFO : EPOCH 1 - PROGRESS: at 32.01% examples, 261684 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:23,496 : INFO : EPOCH 1 - PROGRESS: at 34.84% examples, 274385 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:24,520 : INFO : EPOCH 1 - PROGRESS: at 38.82% examples, 284345 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:25,529 : INFO : EPOCH 1 - PROGRESS: at 42.69% examples, 292160 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:26,535 : INFO : EPOCH 1 - PROGRESS: at 46.85% examples, 299060 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:27,540 : INFO : EPOCH 1 - PROGRESS: at 50.94% examples, 306187 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:28,544 : INFO : EPOCH 1 - PROGRESS: at 54.79% examples, 311770 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:29,565 : INFO : EPOCH 1 - PROGRESS: at 58.65% examples, 317492 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:30,581 : INFO : EPOCH 1 - PROGRESS: at 62.89% examples, 322261 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:31,596 : INFO : EPOCH 1 - PROGRESS: at 67.15% examples, 327017 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:32,627 : INFO : EPOCH 1 - PROGRESS: at 71.37% examples, 331123 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:33,649 : INFO : EPOCH 1 - PROGRESS: at 75.25% examples, 334886 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:34,653 : INFO : EPOCH 1 - PROGRESS: at 79.17% examples, 338713 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:35,656 : INFO : EPOCH 1 - PROGRESS: at 83.00% examples, 341608 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:36,679 : INFO : EPOCH 1 - PROGRESS: at 86.87% examples, 344693 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:37,695 : INFO : EPOCH 1 - PROGRESS: at 90.50% examples, 347854 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:38,702 : INFO : EPOCH 1 - PROGRESS: at 93.93% examples, 351004 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:39,705 : INFO : EPOCH 1 - PROGRESS: at 97.58% examples, 353570 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:40,254 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-02 09:24:40,260 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-02 09:24:40,262 : INFO : EPOCH - 1 : training on 11925051 raw words (11123164 effective words) took 31.3s, 355165 effective words/s\n",
            "2022-03-02 09:24:41,281 : INFO : EPOCH 2 - PROGRESS: at 3.54% examples, 429029 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:42,289 : INFO : EPOCH 2 - PROGRESS: at 7.31% examples, 433690 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:43,313 : INFO : EPOCH 2 - PROGRESS: at 11.20% examples, 429626 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:44,327 : INFO : EPOCH 2 - PROGRESS: at 15.33% examples, 428882 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:45,346 : INFO : EPOCH 2 - PROGRESS: at 19.54% examples, 426351 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:46,352 : INFO : EPOCH 2 - PROGRESS: at 23.52% examples, 424860 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:47,370 : INFO : EPOCH 2 - PROGRESS: at 27.48% examples, 423811 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:48,390 : INFO : EPOCH 2 - PROGRESS: at 31.22% examples, 425491 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:49,391 : INFO : EPOCH 2 - PROGRESS: at 34.10% examples, 428137 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:50,411 : INFO : EPOCH 2 - PROGRESS: at 37.96% examples, 427673 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:51,438 : INFO : EPOCH 2 - PROGRESS: at 42.00% examples, 428210 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:52,450 : INFO : EPOCH 2 - PROGRESS: at 46.54% examples, 429010 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:53,470 : INFO : EPOCH 2 - PROGRESS: at 50.59% examples, 429353 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:54,473 : INFO : EPOCH 2 - PROGRESS: at 54.71% examples, 429695 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:55,475 : INFO : EPOCH 2 - PROGRESS: at 58.65% examples, 430687 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:56,483 : INFO : EPOCH 2 - PROGRESS: at 62.89% examples, 430167 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:57,512 : INFO : EPOCH 2 - PROGRESS: at 67.24% examples, 430281 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:58,540 : INFO : EPOCH 2 - PROGRESS: at 71.52% examples, 430318 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:24:59,540 : INFO : EPOCH 2 - PROGRESS: at 75.47% examples, 430386 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:00,552 : INFO : EPOCH 2 - PROGRESS: at 79.29% examples, 430300 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:01,572 : INFO : EPOCH 2 - PROGRESS: at 83.25% examples, 430128 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:02,598 : INFO : EPOCH 2 - PROGRESS: at 87.21% examples, 430262 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:03,607 : INFO : EPOCH 2 - PROGRESS: at 90.83% examples, 430607 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:04,618 : INFO : EPOCH 2 - PROGRESS: at 94.52% examples, 430917 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:05,645 : INFO : EPOCH 2 - PROGRESS: at 98.16% examples, 431166 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:06,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-02 09:25:06,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-02 09:25:06,093 : INFO : EPOCH - 2 : training on 11925051 raw words (11122004 effective words) took 25.8s, 430756 effective words/s\n",
            "2022-03-02 09:25:07,109 : INFO : EPOCH 3 - PROGRESS: at 3.58% examples, 438108 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:08,119 : INFO : EPOCH 3 - PROGRESS: at 7.53% examples, 442364 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:09,150 : INFO : EPOCH 3 - PROGRESS: at 11.46% examples, 440046 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:10,154 : INFO : EPOCH 3 - PROGRESS: at 15.86% examples, 440347 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:11,177 : INFO : EPOCH 3 - PROGRESS: at 20.20% examples, 438866 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:25:12,208 : INFO : EPOCH 3 - PROGRESS: at 24.40% examples, 438343 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:13,218 : INFO : EPOCH 3 - PROGRESS: at 28.51% examples, 437056 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:14,226 : INFO : EPOCH 3 - PROGRESS: at 32.01% examples, 436345 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:15,240 : INFO : EPOCH 3 - PROGRESS: at 34.84% examples, 437011 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:16,243 : INFO : EPOCH 3 - PROGRESS: at 38.82% examples, 436785 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:17,245 : INFO : EPOCH 3 - PROGRESS: at 42.78% examples, 435702 words/s, in_qsize 2, out_qsize 1\n",
            "2022-03-02 09:25:18,263 : INFO : EPOCH 3 - PROGRESS: at 47.26% examples, 435655 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:19,290 : INFO : EPOCH 3 - PROGRESS: at 51.48% examples, 435299 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:20,307 : INFO : EPOCH 3 - PROGRESS: at 55.40% examples, 435721 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:25:21,323 : INFO : EPOCH 3 - PROGRESS: at 59.43% examples, 435632 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:22,345 : INFO : EPOCH 3 - PROGRESS: at 63.96% examples, 435552 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:23,357 : INFO : EPOCH 3 - PROGRESS: at 68.22% examples, 435747 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:24,372 : INFO : EPOCH 3 - PROGRESS: at 72.40% examples, 436095 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:25,395 : INFO : EPOCH 3 - PROGRESS: at 76.53% examples, 436007 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:25:26,401 : INFO : EPOCH 3 - PROGRESS: at 80.54% examples, 436301 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:27,434 : INFO : EPOCH 3 - PROGRESS: at 84.59% examples, 436028 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:28,446 : INFO : EPOCH 3 - PROGRESS: at 88.42% examples, 436407 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:29,481 : INFO : EPOCH 3 - PROGRESS: at 92.17% examples, 436148 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:30,490 : INFO : EPOCH 3 - PROGRESS: at 95.83% examples, 436216 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:31,511 : INFO : EPOCH 3 - PROGRESS: at 99.55% examples, 436052 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:31,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-02 09:25:31,596 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-02 09:25:31,599 : INFO : EPOCH - 3 : training on 11925051 raw words (11123589 effective words) took 25.5s, 436259 effective words/s\n",
            "2022-03-02 09:25:32,636 : INFO : EPOCH 4 - PROGRESS: at 3.58% examples, 428156 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:33,647 : INFO : EPOCH 4 - PROGRESS: at 7.43% examples, 432688 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:34,654 : INFO : EPOCH 4 - PROGRESS: at 11.30% examples, 433911 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:35,663 : INFO : EPOCH 4 - PROGRESS: at 15.56% examples, 432920 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:36,686 : INFO : EPOCH 4 - PROGRESS: at 19.80% examples, 431069 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:37,699 : INFO : EPOCH 4 - PROGRESS: at 23.89% examples, 429937 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:38,729 : INFO : EPOCH 4 - PROGRESS: at 28.03% examples, 429976 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:39,734 : INFO : EPOCH 4 - PROGRESS: at 31.74% examples, 431533 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:40,747 : INFO : EPOCH 4 - PROGRESS: at 34.71% examples, 434786 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:41,757 : INFO : EPOCH 4 - PROGRESS: at 38.66% examples, 434428 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:42,765 : INFO : EPOCH 4 - PROGRESS: at 42.69% examples, 434185 words/s, in_qsize 2, out_qsize 1\n",
            "2022-03-02 09:25:43,784 : INFO : EPOCH 4 - PROGRESS: at 47.12% examples, 434229 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:25:44,794 : INFO : EPOCH 4 - PROGRESS: at 51.23% examples, 433809 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:45,800 : INFO : EPOCH 4 - PROGRESS: at 55.17% examples, 433629 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:46,812 : INFO : EPOCH 4 - PROGRESS: at 59.19% examples, 434154 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:25:47,829 : INFO : EPOCH 4 - PROGRESS: at 63.55% examples, 433756 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:48,835 : INFO : EPOCH 4 - PROGRESS: at 67.75% examples, 433651 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:49,849 : INFO : EPOCH 4 - PROGRESS: at 71.95% examples, 433726 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:50,851 : INFO : EPOCH 4 - PROGRESS: at 75.96% examples, 433719 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:25:51,861 : INFO : EPOCH 4 - PROGRESS: at 79.93% examples, 434017 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:52,884 : INFO : EPOCH 4 - PROGRESS: at 83.92% examples, 434049 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:53,902 : INFO : EPOCH 4 - PROGRESS: at 87.90% examples, 434443 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:54,920 : INFO : EPOCH 4 - PROGRESS: at 91.59% examples, 434565 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:55,921 : INFO : EPOCH 4 - PROGRESS: at 95.29% examples, 434854 words/s, in_qsize 3, out_qsize 1\n",
            "2022-03-02 09:25:56,930 : INFO : EPOCH 4 - PROGRESS: at 99.04% examples, 435287 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:57,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-02 09:25:57,162 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-02 09:25:57,166 : INFO : EPOCH - 4 : training on 11925051 raw words (11123061 effective words) took 25.6s, 435155 effective words/s\n",
            "2022-03-02 09:25:58,197 : INFO : EPOCH 5 - PROGRESS: at 3.54% examples, 421678 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:25:59,218 : INFO : EPOCH 5 - PROGRESS: at 7.31% examples, 427209 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:00,245 : INFO : EPOCH 5 - PROGRESS: at 11.25% examples, 427681 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:26:01,284 : INFO : EPOCH 5 - PROGRESS: at 15.42% examples, 425000 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:02,295 : INFO : EPOCH 5 - PROGRESS: at 19.70% examples, 425728 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:03,357 : INFO : EPOCH 5 - PROGRESS: at 23.91% examples, 423626 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:26:04,372 : INFO : EPOCH 5 - PROGRESS: at 26.55% examples, 402554 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:26:05,399 : INFO : EPOCH 5 - PROGRESS: at 30.50% examples, 406183 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:06,434 : INFO : EPOCH 5 - PROGRESS: at 33.76% examples, 410575 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:07,444 : INFO : EPOCH 5 - PROGRESS: at 37.21% examples, 413997 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:08,450 : INFO : EPOCH 5 - PROGRESS: at 41.20% examples, 414888 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:09,450 : INFO : EPOCH 5 - PROGRESS: at 45.28% examples, 416532 words/s, in_qsize 4, out_qsize 0\n",
            "2022-03-02 09:26:10,460 : INFO : EPOCH 5 - PROGRESS: at 49.63% examples, 418095 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:11,485 : INFO : EPOCH 5 - PROGRESS: at 53.57% examples, 419185 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:12,507 : INFO : EPOCH 5 - PROGRESS: at 57.83% examples, 420469 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:13,536 : INFO : EPOCH 5 - PROGRESS: at 62.16% examples, 421089 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:14,553 : INFO : EPOCH 5 - PROGRESS: at 66.43% examples, 421452 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:15,560 : INFO : EPOCH 5 - PROGRESS: at 70.39% examples, 421958 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:16,562 : INFO : EPOCH 5 - PROGRESS: at 74.57% examples, 422397 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:17,562 : INFO : EPOCH 5 - PROGRESS: at 78.40% examples, 422647 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:18,584 : INFO : EPOCH 5 - PROGRESS: at 82.41% examples, 423163 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:19,611 : INFO : EPOCH 5 - PROGRESS: at 86.27% examples, 423570 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:20,634 : INFO : EPOCH 5 - PROGRESS: at 90.10% examples, 423928 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:21,652 : INFO : EPOCH 5 - PROGRESS: at 93.38% examples, 424424 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:22,669 : INFO : EPOCH 5 - PROGRESS: at 97.23% examples, 424772 words/s, in_qsize 3, out_qsize 0\n",
            "2022-03-02 09:26:23,331 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-02 09:26:23,336 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-02 09:26:23,339 : INFO : EPOCH - 5 : training on 11925051 raw words (11123102 effective words) took 26.2s, 425075 effective words/s\n",
            "2022-03-02 09:26:23,341 : INFO : Word2Vec lifecycle event {'msg': 'training on 59625255 raw words (55614920 effective words) took 134.4s, 413738 effective words/s', 'datetime': '2022-03-02T09:26:23.341788', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'train'}\n",
            "2022-03-02 09:26:23,344 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=33071, vector_size=300, alpha=0.025)', 'datetime': '2022-03-02T09:26:23.344933', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.similar_by_word('sushi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE5_ygby8X5T",
        "outputId": "5809218a-88f1-4b1e-a720-4b70df5c905a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pastry', 0.6883001327514648),\n",
              " ('salad', 0.6454644203186035),\n",
              " ('chicken', 0.6405736804008484),\n",
              " ('fry', 0.6381990909576416),\n",
              " ('dessert', 0.6287106871604919),\n",
              " ('sous', 0.617621123790741),\n",
              " ('bartender', 0.6161249876022339),\n",
              " ('soup', 0.6134330034255981),\n",
              " ('finisher', 0.6032063364982605),\n",
              " ('chefs', 0.6014286875724792)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check out cosine similarity for some word-vectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "ifCDmQY19OQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pizza = w2v_model.wv['pizza'].reshape(1,300)\n",
        "pasta = w2v_model.wv['pasta'].reshape(1,300)\n",
        "sushi = w2v_model.wv['sushi'].reshape(1,300)\n",
        "uber = w2v_model.wv['uber'].reshape(1,300)"
      ],
      "metadata": {
        "id": "bY7kTxCeD2V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(pizza, uber)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6rxuM9hEi4k",
        "outputId": "4fb7dd23-9dbe-4012-fee0-77ea6b5a8f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13147064]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(pizza, pasta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPihJ-JxE1vl",
        "outputId": "000ebaa2-4ff5-456f-ad7d-dc15f415848d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3657799]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.save('w2v_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgXKUnoaE7mH",
        "outputId": "a55c8143-85e7-4df8-b4b5-1016beb2847c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-02 10:02:12,720 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'w2v_model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-03-02T10:02:12.720010', 'gensim': '4.1.2', 'python': '3.7.12 (default, Jan 15 2022, 18:48:18) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'saving'}\n",
            "2022-03-02 10:02:12,730 : INFO : not storing attribute cum_table\n",
            "2022-03-02 10:02:13,076 : INFO : saved w2v_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function for avg-embeddings \n",
        "# (in older versions of gensim it's not key_to_index but vocab)\n",
        "\n",
        "def get_mean_vector(word2vec_model, words):\n",
        "    # remove out-of-vocabulary words\n",
        "    words = [word for word in words if word in w2v_model.wv.key_to_index]\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(word2vec_model.wv[words], axis=0)\n",
        "    else:\n",
        "        return []"
      ],
      "metadata": {
        "id": "pIY1r6Y9FIE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_jobs['clean_text'][0]"
      ],
      "metadata": {
        "id": "vK1120D_Hf3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_mean_vector(w2v_model, df_jobs['clean_text'][0])"
      ],
      "metadata": {
        "id": "FQI6HgVVHeno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform all texts into avg-vec-repre\n",
        "avg_job_vecs = df_jobs['clean_text'].map(lambda t: get_mean_vector(w2v_model, t))"
      ],
      "metadata": {
        "id": "AJBAHQLpHcwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_job_vecs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns6r2RvhIAY2",
        "outputId": "98384f0f-9a43-4892-cd67-4acdb9b81191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [-0.38937545, 0.39502305, -0.24858037, -0.5289...\n",
              "1    [0.008985659, 0.005536845, -0.30841076, -0.731...\n",
              "2    [0.006986467, -0.0059137023, -0.026989335, -0....\n",
              "3    [-0.37293038, 0.7175547, -0.30870807, -0.30775...\n",
              "4    [0.09119703, 0.4008965, 0.34726006, -0.4725212...\n",
              "5    [0.23849797, 0.06390896, 0.42710426, -0.540001...\n",
              "6    [-0.1828821, 0.62840605, -0.3854589, -0.557041...\n",
              "7    [-0.060302176, 0.1282239, -0.047130395, -0.608...\n",
              "8    [-0.036706682, -0.026592985, 0.4509321, -0.682...\n",
              "9    [-0.18551093, -0.016812475, -0.20467716, -0.46...\n",
              "Name: clean_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate vectors from list to matrix\n",
        "avg_job_vecs = np.vstack(avg_job_vecs)"
      ],
      "metadata": {
        "id": "howy48y5HuaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_job_vecs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_jldWa2IJfd",
        "outputId": "9f18e289-2031-43b3-9a41-ef1c7b01b9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84090, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate similarity to 1 article\n",
        "sims = cosine_similarity(avg_job_vecs[0].reshape(1,300), avg_job_vecs)"
      ],
      "metadata": {
        "id": "jcQ24fiSIMH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QUgm14MIdqT",
        "outputId": "77bbf1dd-a391-4038-c488-0c1c8ff954a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33396965, 0.56535184, ..., 0.47272855, 0.5303309 ,\n",
              "        0.50748646]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract indices\n",
        "ix = np.flip(np.argsort(sims)).tolist()[0][:10]"
      ],
      "metadata": {
        "id": "LEjGgFhYIe6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show results\n",
        "df_jobs['text'][ix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCWAnNbuInJx",
        "outputId": "2c7acb7c-f69e-40b4-cf3e-5f99969e1d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Server @ Tacolicious Server Tacolicious Tacoli...\n",
              "84057    Server @ Kabuto Restaurant Server Kabuto Resta...\n",
              "13448    Server @ BALEENkitchen Server BALEENkitchen  ●...\n",
              "24471    Server @ Exotic Thai Cafe Server Exotic Thai C...\n",
              "84081    Server @ Pizza Antica Server Pizza Antica  ● S...\n",
              "13453    Server @ Gonpachi Server Gonpachi  ● Serve foo...\n",
              "10783    Server @ La Fontaine Restaurant Server La Font...\n",
              "84082    Server @ Giardino Server Giardino  ● Serve foo...\n",
              "84044    Server @ Yuzu Server Yuzu  Yuzu is one of the ...\n",
              "10778    Server @ Far Niente Ristorante Server Far Nien...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# free text query\n",
        "query = 'consultant in legal'\n",
        "\n",
        "query = nlp(query, disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "query = [token.lemma_.lower() for token in query \n",
        "         if token.is_alpha \n",
        "         and not token.is_stop \n",
        "         and not token.is_punct]\n",
        "\n",
        "query = get_mean_vector(w2v_model,query)"
      ],
      "metadata": {
        "id": "cXJRq44wIsNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sims = cosine_similarity(query.reshape(1,300), avg_job_vecs)\n",
        "ix = np.flip(np.argsort(sims)).tolist()[0][:10]\n",
        "df_jobs['text'][ix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei_-rzZjJLGq",
        "outputId": "0b8ac76f-5df5-4ec9-b3f4-fefaa78a2a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53292    HR Consultant - ACA expert needed! @ OfficeTea...\n",
              "56218    Leasing Consultant @ Eastwood Management Corpo...\n",
              "44270    Leasing Consultant Leasing Consultant nan Leas...\n",
              "37578    Legal Assistant/ Project Assistant @ Carolina ...\n",
              "76525    Leasing Consultant @ OfficeTeam Leasing Consul...\n",
              "13691    Administrative Assistant with Leasing Experien...\n",
              "47978    Paralegal/legal assistant/litigation specialis...\n",
              "25871    Legal Writer (part-time) @ Randstad Profession...\n",
              "53752    Senior Consultant   EMCC A2D2 @ GreyStone Staf...\n",
              "10661    Legal assistant @ Law Offices of Bijan Sebasti...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "yD_RVs-IJPhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function that does absolutely nothing...\n",
        "# to be able to use TfidfVectorizer on already tokenized text\n",
        "def dummy_fun(doc):\n",
        "    return doc"
      ],
      "metadata": {
        "id": "P-uHmuzwJ5mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we turn of any preprocessing and align vocabulary with the one\n",
        "# used by our embeddings\n",
        "# that will allow us to use TFIDF vectors to weight the embeddings\n",
        "\n",
        "tfidf = TfidfVectorizer(vocabulary=w2v_model.wv.key_to_index.keys(),\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None)  "
      ],
      "metadata": {
        "id": "6kamxgw1J-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TFIDF matrix (we could also just use that one for search)\n",
        "df_jobs_tfidf = tfidf.fit_transform(df_jobs['clean_text'])"
      ],
      "metadata": {
        "id": "7j_Ak0eXKiBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EwuCdDhwUhB",
        "outputId": "448cc27e-4a9f-4a3b-9b37-27f2888c22b8"
      },
      "source": [
        "# how many word-vectors do we have?\n",
        "len(w2v_model.wv.key_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33071"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2AQI0-AwOLg",
        "outputId": "ef044470-b530-40eb-959c-2ddde4fa3ae5"
      },
      "source": [
        "# one tfidf vector has also 33071 columns - because we provided a vocab\n",
        "df_jobs_tfidf[:1,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x33071 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 27 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb-mE9z2wghs"
      },
      "source": [
        "To get the vectors, we can use the dot-product of the TFIDF vector (or full matrix) with our word embeddings. n-columns (TFIDF) = n-rows (W2V embeddings)\n",
        "\n",
        "![](https://hadrienj.github.io/assets/images/2.2/dot-product.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use np.dot or since Python 3 the @ for matrix-multiplication\n",
        "\n",
        "# let's try\n",
        "df_jobs_tfidf[:1,:] @ w2v_model.wv.vectors"
      ],
      "metadata": {
        "id": "kI3qtGfuMDGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the whole matrix\n",
        "\n",
        "df_jobs_w2v_tfidf = df_jobs_tfidf @ w2v_model.wv.vectors"
      ],
      "metadata": {
        "id": "7GtLOPzOMDxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate similarity to 1 article\n",
        "sims = cosine_similarity(df_jobs_w2v_tfidf[0].reshape(1,300), df_jobs_w2v_tfidf)\n",
        "\n",
        "# extract indices\n",
        "ix = np.flip(np.argsort(sims)).tolist()[0][:10]\n",
        "\n",
        "# show results\n",
        "df_jobs['text'][ix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VfiGKtHMaYr",
        "outputId": "e89f3de8-6605-4fbc-9bf0-ef0b43c19348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Server @ Tacolicious Server Tacolicious Tacoli...\n",
              "84057    Server @ Kabuto Restaurant Server Kabuto Resta...\n",
              "13448    Server @ BALEENkitchen Server BALEENkitchen  ●...\n",
              "84044    Server @ Yuzu Server Yuzu  Yuzu is one of the ...\n",
              "13453    Server @ Gonpachi Server Gonpachi  ● Serve foo...\n",
              "54458    Server @ Sakae Sushi Server Sakae Sushi  Locat...\n",
              "84081    Server @ Pizza Antica Server Pizza Antica  ● S...\n",
              "24471    Server @ Exotic Thai Cafe Server Exotic Thai C...\n",
              "84001    Server @ Waraku Server Waraku We are a newly o...\n",
              "84062    Server @ Kenta Ramen Server Kenta Ramen  New R...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slightly more complex function that includes preprocessing with Spacy\n",
        "# TFIDF transformation and embeddings\n",
        "\n",
        "def get_tfidf_vector(word2vec_model, query):\n",
        "\n",
        "    query = nlp(query, disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "    query = [token.lemma_.lower() for token in query \n",
        "         if token.is_alpha \n",
        "         and not token.is_stop \n",
        "         and not token.is_punct]\n",
        "    if len(query) >= 1:\n",
        "      words = tfidf.transform([query])\n",
        "      return words @ word2vec_model.wv.vectors\n",
        "    else:\n",
        "        return []"
      ],
      "metadata": {
        "id": "ai8Rmt15NHtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = get_tfidf_vector(w2v_model, 'web developer and designer')\n",
        "sims = cosine_similarity(query.reshape(1,300), df_jobs_w2v_tfidf)\n",
        "ix = np.flip(np.argsort(sims)).tolist()[0][:10]\n",
        "df_jobs['text'][ix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD2c1cCENOZr",
        "outputId": "430f5a57-361f-471e-a9cf-a9387f888c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59799    Tableau UI Developer Tableau UI Developer nan ...\n",
              "81172    Jr. Ruby on Rails Developer @ ConsultNet Jr. R...\n",
              "19011    Web Designer (freelance) @ Creative Circle Web...\n",
              "59440    Sr. UX Designer @ Creative Circle Sr. UX Desig...\n",
              "32658    Web Developer @ Creative Circle Web Developer ...\n",
              "41978    Web designer/Front-end developer @ Collabera I...\n",
              "79576    Web Developer @ Creative Circle Web Developer ...\n",
              "34535    Graphic Designer (Print + Web) @ Creative Circ...\n",
              "73957    Web Developer @ Creative Circle Web Developer ...\n",
              "27721    Front End Developer @ ConsultNet Front End Dev...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "64q7soiwNWGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoXE--Xn1sKF"
      },
      "source": [
        "Adding Annoy - Approximate nearest neighbor matching\n",
        "\n",
        "![](https://camo.githubusercontent.com/a056535a8490b4b1aa933808e77207276235a209e97a980119d3e438897e1d36/68747470733a2f2f7261772e6769746875622e636f6d2f73706f746966792f616e6e6f792f6d61737465722f616e6e2e706e67)\n",
        "\n",
        "calculating cosines is great for small datasets (like ours) that gets more problematic once things get larger - here on-disk ANN approximation is the solution (we are talking 1M+ observations - when the vectorized matrices get too large)\n",
        "\n",
        "I work easilly with colelctions of 40+ million with annoy...runs quick :-)\n",
        "\n",
        "check out: https://github.com/spotify/annoy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJOtwoti2EGZ",
        "outputId": "3842907e-abbb-47ee-8f65-7e1a50ed864c"
      },
      "source": [
        "!pip install -q annoy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 81 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 102 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 122 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 143 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 266 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 286 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 307 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 317 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 337 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 358 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 378 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 389 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 399 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 409 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 430 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 440 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 450 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 460 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 471 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 481 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 501 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 512 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 522 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 532 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 542 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 552 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 563 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 573 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 593 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 614 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 634 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 646 kB 22.1 MB/s \n",
            "\u001b[?25h  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z43PYpQ2EZA"
      },
      "source": [
        "from annoy import AnnoyIndex\n",
        "\n",
        "# instatiate a search tree (with shape n/300)\n",
        "t = AnnoyIndex(df_jobs_w2v_tfidf.shape[1], 'angular') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAQYVsU42Rfe",
        "outputId": "46371d97-826a-477d-a057-b592b4f2c727"
      },
      "source": [
        "# we will build that on disk (can reuse later if we store it somwhere)\n",
        "\n",
        "t.on_disk_build('jobs_search_tree.annoy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we add all our vectors - line by line to the tree\n",
        "# along with an index (here i - running index)\n",
        "for i in tqdm.tqdm(range(df_jobs_w2v_tfidf.shape[0]),position=0, leave=True):\n",
        "    t.add_item(i, df_jobs_w2v_tfidf[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r2qMevDPKDS",
        "outputId": "f11a7678-4052-49e9-b7dc-c2c606462559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84090/84090 [00:05<00:00, 14927.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we build the search tree (that creates partitions within the data-a bit like clustering)\n",
        "# thereafter search will be performed within the nearest partitions (that reduces search time A LOT)\n",
        "t.build(50, n_jobs=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE-Zn4gqPSRV",
        "outputId": "3e84ba1a-00a4-4b80-f819-ef2ea9384e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.get_nns_by_vector(df_jobs_w2v_tfidf[0], n=10, include_distances=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzuLw1qOPhGW",
        "outputId": "33a4309a-06de-4331-87fc-936d4e3ef680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 84057, 13448, 84044, 13453, 54458, 84081, 24471, 84001, 84062],\n",
              " [0.0,\n",
              "  0.443498432636261,\n",
              "  0.471523642539978,\n",
              "  0.4842592477798462,\n",
              "  0.4921287000179291,\n",
              "  0.49800676107406616,\n",
              "  0.49911630153656006,\n",
              "  0.5047510266304016,\n",
              "  0.5048704743385315,\n",
              "  0.514162003993988])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can search by index\n",
        "knn_search = t.get_nns_by_item(0, n=10, include_distances=True)\n",
        "df_jobs['text'][knn_search[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcZE-47YP7aF",
        "outputId": "5d3b98fc-e0bb-42a1-fdaa-7a9471f85814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Server @ Tacolicious Server Tacolicious Tacoli...\n",
              "84057    Server @ Kabuto Restaurant Server Kabuto Resta...\n",
              "13448    Server @ BALEENkitchen Server BALEENkitchen  ●...\n",
              "84044    Server @ Yuzu Server Yuzu  Yuzu is one of the ...\n",
              "13453    Server @ Gonpachi Server Gonpachi  ● Serve foo...\n",
              "54458    Server @ Sakae Sushi Server Sakae Sushi  Locat...\n",
              "84081    Server @ Pizza Antica Server Pizza Antica  ● S...\n",
              "24471    Server @ Exotic Thai Cafe Server Exotic Thai C...\n",
              "84001    Server @ Waraku Server Waraku We are a newly o...\n",
              "84062    Server @ Kenta Ramen Server Kenta Ramen  New R...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can search by vector\n",
        "knn_search = t.get_nns_by_vector(df_jobs_w2v_tfidf[0], n=10, include_distances=True)\n",
        "df_jobs['text'][knn_search[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWdDmWZbQFCB",
        "outputId": "1c5c97f3-90cc-4140-efa5-8ff7af86d5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Server @ Tacolicious Server Tacolicious Tacoli...\n",
              "84057    Server @ Kabuto Restaurant Server Kabuto Resta...\n",
              "13448    Server @ BALEENkitchen Server BALEENkitchen  ●...\n",
              "84044    Server @ Yuzu Server Yuzu  Yuzu is one of the ...\n",
              "13453    Server @ Gonpachi Server Gonpachi  ● Serve foo...\n",
              "54458    Server @ Sakae Sushi Server Sakae Sushi  Locat...\n",
              "84081    Server @ Pizza Antica Server Pizza Antica  ● S...\n",
              "24471    Server @ Exotic Thai Cafe Server Exotic Thai C...\n",
              "84001    Server @ Waraku Server Waraku We are a newly o...\n",
              "84062    Server @ Kenta Ramen Server Kenta Ramen  New R...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# also with a free query\n",
        "query = get_tfidf_vector(w2v_model, 'web developer and designer')\n",
        "\n",
        "knn_search = t.get_nns_by_vector(query[0], n=10, include_distances=True) \n",
        "# need to index [0] our matrix - annoy likes vectors - that's opposite from sklearn cosine\n",
        "\n",
        "df_jobs['text'][knn_search[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuOWRIpnQWR4",
        "outputId": "9087cce9-2616-4671-afce-6521c9fb7e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59799    Tableau UI Developer Tableau UI Developer nan ...\n",
              "81172    Jr. Ruby on Rails Developer @ ConsultNet Jr. R...\n",
              "19011    Web Designer (freelance) @ Creative Circle Web...\n",
              "59440    Sr. UX Designer @ Creative Circle Sr. UX Desig...\n",
              "32658    Web Developer @ Creative Circle Web Developer ...\n",
              "41978    Web designer/Front-end developer @ Collabera I...\n",
              "79576    Web Developer @ Creative Circle Web Developer ...\n",
              "34535    Graphic Designer (Print + Web) @ Creative Circ...\n",
              "73957    Web Developer @ Creative Circle Web Developer ...\n",
              "27721    Front End Developer @ ConsultNet Front End Dev...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "la4UVHUpQb5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}